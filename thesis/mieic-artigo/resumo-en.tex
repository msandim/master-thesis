%-----------------------------------------------
% Template para criação de resumos de projectos/dissertação
% jlopes AT fe.up.pt,   Fri Jul  3 11:08:59 2009
%-----------------------------------------------

\documentclass[9pt,a4paper]{extarticle}

%% English version: comment first, uncomment second
%\usepackage[portuguese]{babel}  % Portuguese
\usepackage[english]{babel}     % English
\usepackage{graphicx}           % images .png or .pdf w/ pdflatex OR .eps w/ latex
\usepackage{times}              % use Times type-1 fonts
\usepackage[utf8]{inputenc}     % 8 bits using UTF-8
\usepackage{url}                % URLs
\usepackage{multicol}           % twocolumn, etc
\usepackage{float}              % improve figures & tables floating
\usepackage[tableposition=top]{caption} % captions
%% English version: comment first (maybe)
%\usepackage{indentfirst}        % portuguese standard for paragraphs
%\usepackage{parskip}
\usepackage[backend=biber, sorting=none]{biblatex}
\addbibresource{refs.bib}

%% page layout
\usepackage[a4paper,margin=30mm,noheadfoot]{geometry}

%% space between columns
\columnsep 12mm

%% headers & footers
\pagestyle{empty}

%% figure & table caption
\captionsetup{figurename=Fig.,tablename=Tab.,labelsep=endash,font=bf,skip=.5\baselineskip}

%% heading
\makeatletter
\renewcommand*{\@seccntformat}[1]{%
  \csname the#1\endcsname.\quad
}
\makeatother

%% avoid widows and orphans
\clubpenalty=300
\widowpenalty=300

\begin{document}

\title{\vspace*{-8mm}\textbf{\textsc{Using Stacked Generalization for Anomaly Detection}}}
\author{\emph{Miguel Oliveira Sandim}\\[2mm]
\small{Dissertation developed under the supervision of \emph{Prof.\ Carlos Soares}}\\
\small{and co-supervision of \emph{Prof. Bernhard Pfahringer}}}
\date{September 19, 2017}
\maketitle
%no page number 
\thispagestyle{empty}

\vspace*{-4mm}\noindent\rule{\textwidth}{0.4pt}\vspace*{4mm}

\begin{multicols}{2}

\section{Motivation}\label{sec:motiva}

Data Mining has become an important field in the modern world, given the large number of possible applications in many different domains such as marketing, medical research, computer vision, social network analysis, intrusion detection and fraud detection \cite{Aggarwal:2015:DMT:2778285}.

Anomaly Detection is a very specific but significant topic in this field, given the high number of domains in which it can be applied \cite{Kandhari2009}. In fact, the problem that motivates this field is a very common one and can be easily translated into this question: given a certain amount of data, is it possible to detect observations that deviate from the normal behavior of the data?
This question can arise, e.g. in areas such as credit card fraud detection or machine condition monitoring.

The literature regarding Anomaly Detection techniques is very extensive and diverse, with a wide range of techniques that can have different outputs (either an \textit{anomaly score} that indicates how much of a data instance in a dataset is an \textit{anomaly}, or a label -- \textit{anomalous} or \textit{normal}), as well as different assumptions (e.g. density based techniques have different underlying assumptions than clustering based techniques).
This heterogeneity within Anomaly Detection techniques may cause different techniques to behave differently on the same dataset, which makes the task of choosing the right technique(s) for a specific domain very difficult and data-dependent.

\section{Goals}\label{sec:goals}

This dissertation intends to address this issue, by using several Anomaly Detection techniques at the same time and then combining their outputs into a single one.
This is the idea behind Ensemble Learning methods, which work by generating a group of models (which is designated by \textit{ensemble}) and then combining their predictions into one.
Ensemble Learning has proven to improve performance in machine learning applications such as classification, regression, time-series analysis and recommender systems \cite{Aggarwal:2013:OA:2436823}.
More specifically this dissertation explores a Stacked Generalization method, which consists in using an extra model that \textit{learns} the best way of combining the group of models.

Therefore this thesis intends to answer the following main research question:

\begin{itemize}
	\item Can a Stacked Generalization method improve the performance of Anomaly Detection techniques, more specifically the performance of the best technique for a given dataset?
\end{itemize}


\section{Description of the Dissertation}\label{sec:work}

This research work was divided in two different research studies.
The first study focused on the performance and diversity of the Anomaly Detection techniques selected and had the following goals:

\begin{itemize}
	\item Study the performance and diversity of different types of Anomaly Detection techniques on
	several well-known datasets;
	\item Assess if this experimental setup contains \textit{accurate} and \textit{diverse} models.
\end{itemize}

The second one focused on the application of Stacked Generalization to the techniques selected and had the following goals:

\begin{itemize}
	\item Determine if combining several Anomaly Detection techniques with a model improves the
	performance of each of the Anomaly Detection techniques used in this study;
	\item If so, determine how much the performance is improved.
\end{itemize}

This research work included several state of the art Anomaly Detection techniques:  Classification and Regression Trees (CART),  Support Vector Machine (SVM), Naive Bayes (NB),  Random Forest (RF), Multilayer Perceptron (MLP), One-Class SVM, k-means, Density-based Spatial Clustering of Applications with Noise (DBSCAN) and Local Outlier Factor (LOF).

Several datasets were used in order to access the performance of the Anomaly Detection techniques and Ensemble Learning methods.
These datasets were previously used in the Anomaly Detection literature and gathered by \textcite{Campos2016}.

\section{Conclusions}\label{sec:conclui}

Then main conclusions of this dissertation can be briefly summarized as follows:

\begin{itemize}	
	\item Most of the Anomaly Detection techniques used in this study are \textit{accurate} and \textit{diverse} in the datasets used, therefore having the necessary conditions for the Stacking method over-performing the best technique in each dataset;
	\item The application of the Stacking method guaranteed higher F1 values than the best Anomaly Detection technique on more than half of the datasets used;
	\item There is no clear indication whether including Anomaly Detection techniques from different learning modes guarantees higher F1 values. In the datasets where this was true, the best combination was including techniques from all the learning modes available;
	\item There is not a meta-classifier that clearly outperformed the others in terms of F1 on the datasets, so choosing the appropriate one seems to be very dependent on the dataset;
	\item Replacing the meta-classifier with the Majority Voting method improved the F1 value on even more datasets, with also a higher mean improvement on the F1. In this case, ensembles with tree-based Anomaly Detection techniques only (CART and Random Forest) were the ones with higher F1 values on most datasets.
\end{itemize}


%%English version: comment first, uncomment second
%\bibliographystyle{unsrt-pt}  % numeric, unsorted refs
%\bibliographystyle{unsrt}  % numeric, unsorted refs
%\bibliography{refs}
\printbibliography

\end{multicols}

\end{document}
